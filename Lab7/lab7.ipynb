{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43ff66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 Accuracy (PlayCricket): 0.39999999999999997\n",
      "C4.5 Accuracy (PlayCricket): 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Q1: Decision Tree (ID3 & C4.5) on playCricket.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"playCricket.csv\")\n",
    "data.head()\n",
    "\n",
    "# Convert continuous columns to boolean if any (classification task)\n",
    "for col in data.columns[:-1]:\n",
    "    if data[col].dtype != 'object':\n",
    "        thr = data[col].median()\n",
    "        data[col] = (data[col] > thr).astype(str)\n",
    "\n",
    "# Helper functions\n",
    "def entropy(y):\n",
    "    vals, counts = np.unique(y, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "    return -np.sum(probs * np.log2(probs + 1e-9))\n",
    "\n",
    "def info_gain(X, y, feature):\n",
    "    vals = np.unique(X[feature])\n",
    "    total_entropy = entropy(y)\n",
    "    weighted_entropy = sum((len(X[X[feature]==v]) / len(X)) * entropy(y[X[feature]==v]) for v in vals)\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def split_gain_ratio(X, y, feature):\n",
    "    vals = np.unique(X[feature])\n",
    "    split_info = -np.sum([(len(X[X[feature]==v])/len(X))*np.log2(len(X[X[feature]==v])/len(X)) for v in vals])\n",
    "    return info_gain(X, y, feature) / (split_info + 1e-9)\n",
    "\n",
    "# ID3 Algorithm\n",
    "def id3(X, y):\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return y.iloc[0]\n",
    "    if len(X.columns) == 0:\n",
    "        return y.mode()[0]\n",
    "    gains = {col: info_gain(X, y, col) for col in X.columns}\n",
    "    best = max(gains, key=gains.get)\n",
    "    tree = {best: {}}\n",
    "    for val in np.unique(X[best]):\n",
    "        subX = X[X[best]==val].drop(columns=[best])\n",
    "        subY = y[X[best]==val]\n",
    "        tree[best][val] = id3(subX, subY)\n",
    "    return tree\n",
    "\n",
    "# C4.5 Algorithm\n",
    "def c45(X, y):\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return y.iloc[0]\n",
    "    if len(X.columns) == 0:\n",
    "        return y.mode()[0]\n",
    "    ratios = {col: split_gain_ratio(X, y, col) for col in X.columns}\n",
    "    best = max(ratios, key=ratios.get)\n",
    "    tree = {best: {}}\n",
    "    for val in np.unique(X[best]):\n",
    "        subX = X[X[best]==val].drop(columns=[best])\n",
    "        subY = y[X[best]==val]\n",
    "        tree[best][val] = c45(subX, subY)\n",
    "    return tree\n",
    "\n",
    "# Simple predict function\n",
    "def predict(tree, sample):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    feature = list(tree.keys())[0]\n",
    "    val = sample[feature]\n",
    "    if val in tree[feature]:\n",
    "        return predict(tree[feature][val], sample)\n",
    "    return list(tree[feature].values())[0]\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for algo in [\"ID3\", \"C4.5\"]:\n",
    "    accs = []\n",
    "    for train, test in kf.split(X):\n",
    "        X_train, y_train = X.iloc[train], y.iloc[train]\n",
    "        X_test, y_test = X.iloc[test], y.iloc[test]\n",
    "        tree = id3(X_train, y_train) if algo==\"ID3\" else c45(X_train, y_train)\n",
    "        preds = [predict(tree, row) for _, row in X_test.iterrows()]\n",
    "        accs.append(accuracy_score(y_test, preds))\n",
    "    print(f\"{algo} Accuracy (PlayCricket):\", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3 Accuracy (Drug200): 0.8800000000000001\n",
      "C4.5 Accuracy (Drug200): 0.8800000000000001\n"
     ]
    }
   ],
   "source": [
    "# Q2: Decision Tree (ID3 & C4.5) on drug_200.csv\n",
    "\n",
    "data2 = pd.read_csv(\"drug_200.csv\")\n",
    "data2.head()\n",
    "\n",
    "# Convert numerical columns to boolean if classification\n",
    "for col in data2.columns[:-1]:\n",
    "    if data2[col].dtype != 'object':\n",
    "        thr = data2[col].median()\n",
    "        data2[col] = (data2[col] > thr).astype(str)\n",
    "\n",
    "X, y = data2.iloc[:,:-1], data2.iloc[:,-1]\n",
    "\n",
    "for algo in [\"ID3\", \"C4.5\"]:\n",
    "    accs = []\n",
    "    for train, test in kf.split(X):\n",
    "        X_train, y_train = X.iloc[train], y.iloc[train]\n",
    "        X_test, y_test = X.iloc[test], y.iloc[test]\n",
    "        tree = id3(X_train, y_train) if algo==\"ID3\" else c45(X_train, y_train)\n",
    "        preds = [predict(tree, row) for _, row in X_test.iterrows()]\n",
    "        accs.append(accuracy_score(y_test, preds))\n",
    "    print(f\"{algo} Accuracy (Drug200):\", np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537294cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Decision Tree:\n",
      "Average R2: -0.15888089862827232\n",
      "Average RMSE: 96.59973085862343\n"
     ]
    }
   ],
   "source": [
    "# Q3: Decision Tree Regression on petrol_consumption.csv\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "data3 = pd.read_csv(\"petrol_consumption.csv\")\n",
    "data3.head()\n",
    "\n",
    "X = data3.iloc[:,:-1].values\n",
    "y = data3.iloc[:,-1].values\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feat=None, thr=None, left=None, right=None, val=None):\n",
    "        self.feat = feat\n",
    "        self.thr = thr\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.val = val\n",
    "\n",
    "def mse(y):\n",
    "    return np.mean((y - np.mean(y))**2)\n",
    "\n",
    "def best_split(X, y):\n",
    "    best_feat, best_thr, best_gain = None, None, -1\n",
    "    for feat in range(X.shape[1]):\n",
    "        for thr in np.unique(X[:,feat]):\n",
    "            left, right = y[X[:,feat]<=thr], y[X[:,feat]>thr]\n",
    "            if len(left)==0 or len(right)==0: continue\n",
    "            gain = mse(y) - (len(left)/len(y))*mse(left) - (len(right)/len(y))*mse(right)\n",
    "            if gain > best_gain:\n",
    "                best_feat, best_thr, best_gain = feat, thr, gain\n",
    "    return best_feat, best_thr\n",
    "\n",
    "def build_tree(X, y, depth=0, max_depth=5):\n",
    "    if len(np.unique(y))==1 or depth>=max_depth:\n",
    "        return Node(val=np.mean(y))\n",
    "    feat, thr = best_split(X, y)\n",
    "    if feat is None: return Node(val=np.mean(y))\n",
    "    left_idx, right_idx = X[:,feat]<=thr, X[:,feat]>thr\n",
    "    left = build_tree(X[left_idx], y[left_idx], depth+1, max_depth)\n",
    "    right = build_tree(X[right_idx], y[right_idx], depth+1, max_depth)\n",
    "    return Node(feat, thr, left, right)\n",
    "\n",
    "def predict_reg(node, x):\n",
    "    if node.val is not None:\n",
    "        return node.val\n",
    "    if x[node.feat] <= node.thr:\n",
    "        return predict_reg(node.left, x)\n",
    "    else:\n",
    "        return predict_reg(node.right, x)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "r2s, rmses = [], []\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    tree = build_tree(X_train, y_train)\n",
    "    preds = np.array([predict_reg(tree, x) for x in X_test])\n",
    "    r2s.append(r2_score(y_test, preds))\n",
    "    rmses.append(np.sqrt(mean_squared_error(y_test, preds)))\n",
    "\n",
    "print(\"Regression Decision Tree:\")\n",
    "print(\"Average R2:\", np.mean(r2s))\n",
    "print(\"Average RMSE:\", np.mean(rmses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
