{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "K-xN1OInQhvp",
        "outputId": "b6c91767-9dca-4cb9-fea5-af545ab13864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12d12278-3dae-4915-b416-4ec72285579f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12d12278-3dae-4915-b416-4ec72285579f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving breast+cancer.zip to breast+cancer.zip\n",
            "Saving Iris.csv to Iris.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjg7QVscTzrg"
      },
      "outputs": [],
      "source": [
        "import csv, math, random\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_iris_csv(path=\"Iris.csv\"):\n",
        "    X, y = [], []\n",
        "    with open(path, \"r\", newline=\"\") as f:\n",
        "        rdr = csv.DictReader(f)\n",
        "        for row in rdr:\n",
        "            X.append([\n",
        "                float(row[\"SepalLengthCm\"]),\n",
        "                float(row[\"SepalWidthCm\"]),\n",
        "                float(row[\"PetalLengthCm\"]),\n",
        "                float(row[\"PetalWidthCm\"]),\n",
        "            ])\n",
        "            y.append(row[\"Species\"])\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "1MeBGkoNPT3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(X, y, ratios=(0.8, 0.1, 0.1), seed=RANDOM_SEED, stratify=True):\n",
        "    assert abs(sum(ratios)-1.0) < 1e-9\n",
        "    n = len(X)\n",
        "    idxs = list(range(n))\n",
        "    if stratify:\n",
        "        # group by class\n",
        "        by_cls = defaultdict(list)\n",
        "        for i, label in enumerate(y):\n",
        "            by_cls[label].append(i)\n",
        "        train, val, test = [], [], []\n",
        "        for cls, inds in by_cls.items():\n",
        "            random.Random(seed).shuffle(inds)\n",
        "            n_c = len(inds)\n",
        "            n_train = int(ratios[0]*n_c)\n",
        "            n_val   = int(ratios[1]*n_c)\n",
        "            train += inds[:n_train]\n",
        "            val   += inds[n_train:n_train+n_val]\n",
        "            test  += inds[n_train+n_val:]\n",
        "    else:\n",
        "        random.Random(seed).shuffle(idxs)\n",
        "        n_train = int(ratios[0]*n)\n",
        "        n_val   = int(ratios[1]*n)\n",
        "        train, val, test = idxs[:n_train], idxs[n_train:n_train+n_val], idxs[n_train+n_val:]\n",
        "\n",
        "    def take(idxs):\n",
        "        return [X[i] for i in idxs], [y[i] for i in idxs]\n",
        "    return take(train), take(val), take(test)\n"
      ],
      "metadata": {
        "id": "C7YIfDFvPZb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CART Decision Tree (Gini)\n",
        "\n",
        "class TreeNode:\n",
        "    __slots__ = (\"is_leaf\",\"prediction\",\"feature\",\"threshold\",\"left\",\"right\")\n",
        "    def __init__(self, is_leaf, prediction=None, feature=None, threshold=None, left=None, right=None):\n",
        "        self.is_leaf = is_leaf\n",
        "        self.prediction = prediction\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "def gini_impurity(labels):\n",
        "    total = len(labels)\n",
        "    if total == 0: return 0.0\n",
        "    counts = Counter(labels)\n",
        "    return 1.0 - sum((c/total)**2 for c in counts.values())\n",
        "\n",
        "def best_split_numeric(X, y):\n",
        "    n = len(X)\n",
        "    if n <= 1:\n",
        "        return None, None, None\n",
        "    m = len(X[0])\n",
        "    base_imp = gini_impurity(y)\n",
        "    best_gain = 0.0\n",
        "    best_f, best_thr, best_partition = None, None, None\n",
        "\n",
        "    for f in range(m):\n",
        "        # sort by feature f\n",
        "        pairs = sorted(zip(X, y), key=lambda t: t[0][f])\n",
        "        xs = [p[0][f] for p in pairs]\n",
        "        ys = [p[1] for p in pairs]\n",
        "        # candidate thresholds: midpoints between distinct consecutive values\n",
        "        left_counts = Counter()\n",
        "        right_counts = Counter(ys)\n",
        "        left_n = 0\n",
        "        right_n = n\n",
        "        for i in range(n-1):\n",
        "            cls = ys[i]\n",
        "            left_counts[cls] += 1; left_n += 1\n",
        "            right_counts[cls] -= 1; right_n -= 1\n",
        "            if xs[i] == xs[i+1]:\n",
        "                continue\n",
        "            thr = 0.5*(xs[i] + xs[i+1])\n",
        "\n",
        "            # compute gini for left/right\n",
        "            gl = 1.0 - sum((c/left_n)**2 for c in left_counts.values())\n",
        "            gr = 1.0 - sum((c/right_n)**2 for c in right_counts.values())\n",
        "            weighted = (left_n/n)*gl + (right_n/n)*gr\n",
        "            gain = base_imp - weighted\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_f = f\n",
        "                best_thr = thr\n",
        "\n",
        "    if best_f is None:\n",
        "        return None, None, None\n",
        "\n",
        "    # Partition using best split\n",
        "    left_idx = [i for i, x in enumerate(X) if x[best_f] <= best_thr]\n",
        "    right_idx = [i for i, x in enumerate(X) if x[best_f] > best_thr]\n",
        "    return best_f, best_thr, (left_idx, right_idx)\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=10, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow(X, y, depth=0)\n",
        "\n",
        "    def _leaf(self, y):\n",
        "        # majority class\n",
        "        return TreeNode(is_leaf=True, prediction=Counter(y).most_common(1)[0][0])\n",
        "\n",
        "    def _grow(self, X, y, depth):\n",
        "        if depth >= self.max_depth or len(X) < self.min_samples_split or gini_impurity(y) == 0.0:\n",
        "            return self._leaf(y)\n",
        "        f, thr, parts = best_split_numeric(X, y)\n",
        "        if f is None or parts is None:\n",
        "            return self._leaf(y)\n",
        "        left_idx, right_idx = parts\n",
        "        if len(left_idx) == 0 or len(right_idx) == 0:\n",
        "            return self._leaf(y)\n",
        "        Xl = [X[i] for i in left_idx]; yl = [y[i] for i in left_idx]\n",
        "        Xr = [X[i] for i in right_idx]; yr = [y[i] for i in right_idx]\n",
        "        left = self._grow(Xl, yl, depth+1)\n",
        "        right = self._grow(Xr, yr, depth+1)\n",
        "        node = TreeNode(is_leaf=False, feature=f, threshold=thr, left=left, right=right)\n",
        "        return node\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        node = self.root\n",
        "        while not node.is_leaf:\n",
        "            if x[node.feature] <= node.threshold:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node.prediction\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_one(x) for x in X]\n"
      ],
      "metadata": {
        "id": "KS0Hq-OwPeOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging\n",
        "\n",
        "class BaggingClassifier:\n",
        "    def __init__(self, base_params=None, n_estimators=50, max_samples=None, random_state=RANDOM_SEED):\n",
        "        self.base_params = base_params or {}\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples  # None -> len(train)\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = random.Random(self.random_state)\n",
        "        n = len(X)\n",
        "        m = self.max_samples or n\n",
        "        self.trees = []\n",
        "        for t in range(self.n_estimators):\n",
        "            idxs = [rng.randrange(n) for _ in range(m)]  # bootstrap with replacement\n",
        "            Xb = [X[i] for i in idxs]\n",
        "            yb = [y[i] for i in idxs]\n",
        "            tree = DecisionTree(**self.base_params)\n",
        "            tree.fit(Xb, yb)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # majority vote\n",
        "        votes = []\n",
        "        for x in X:\n",
        "            preds = [tree._predict_one(x) for tree in self.trees]\n",
        "            votes.append(Counter(preds).most_common(1)[0][0])\n",
        "        return votes\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return sum(yt==yp for yt, yp in zip(y_true, y_pred))/len(y_true)\n"
      ],
      "metadata": {
        "id": "L7p-jl5GPqTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on Iris\n",
        "\n",
        "X, y = load_iris_csv(\"Iris.csv\")\n",
        "(trainX, trainY), (valX, valY), (testX, testY) = train_val_test_split(X, y, ratios=(0.7,0.15,0.15), seed=RANDOM_SEED, stratify=True)\n",
        "\n",
        "bag = BaggingClassifier(\n",
        "    base_params={\"max_depth\":5, \"min_samples_split\":2},\n",
        "    n_estimators=50,\n",
        "    max_samples=None,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "bag.fit(trainX, trainY)\n",
        "\n",
        "val_pred = bag.predict(valX)\n",
        "test_pred = bag.predict(testX)\n",
        "print(f\"[Iris] Validation accuracy: {accuracy(valY, val_pred):.4f}\")\n",
        "print(f\"[Iris] Test accuracy:       {accuracy(testY, test_pred):.4f}\")"
      ],
      "metadata": {
        "id": "yrvvVlVNPw19",
        "outputId": "13646bdf-6b79-4d0b-999b-3aa47f705753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iris] Validation accuracy: 0.9048\n",
            "[Iris] Test accuracy:       0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breast Cancer"
      ],
      "metadata": {
        "id": "PDxsO_oF0xfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv, math, random, zipfile, os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "NFb0YZcuQrvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "if os.path.exists(\"breast+cancer.zip\"):\n",
        "    with zipfile.ZipFile(\"breast+cancer.zip\",\"r\") as z:\n",
        "        z.extractall(\"breast_cancer_ucI\")  # folder\n",
        "data_path = \"breast_cancer_ucI/breast-cancer.data\"\n",
        "assert os.path.exists(data_path), \"breast-cancer.data not found. Ensure breast+cancer.zip is uploaded.\"\n",
        "\n",
        "def load_breast_cancer_original(path=data_path):\n",
        "    \"\"\"\n",
        "    Returns X as list of lists of strings (categorical, with 'unknown' instead of '?'),\n",
        "    y as list in {-1, +1}, mapping:\n",
        "      'no-recurrence-events' -> +1\n",
        "      'recurrence-events'    -> -1\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    with open(path, \"r\", newline=\"\") as f:\n",
        "        rdr = csv.reader(f)\n",
        "        for row in rdr:\n",
        "            if not row:\n",
        "                continue\n",
        "            # columns per UCI: class, age, menopause, tumor-size, inv-nodes, node-caps, deg-malig, breast, breast-quad, irradiat\n",
        "            cls = row[0].strip()\n",
        "            feats = [c.strip() for c in row[1:]]\n",
        "            feats = [\"unknown\" if v==\"?\" else v for v in feats]\n",
        "            # robust: deg-malig is numeric-ish; still treat as categorical string\n",
        "            if cls == \"no-recurrence-events\":\n",
        "                y.append(+1)\n",
        "            elif cls == \"recurrence-events\":\n",
        "                y.append(-1)\n",
        "            else:\n",
        "                # skip if unexpected label\n",
        "                continue\n",
        "            X.append(feats)\n",
        "    return X, y\n",
        "\n",
        "Xc, yc = load_breast_cancer_original(data_path)\n",
        "\n",
        "def stratified_split(X, y, ratios=(0.8,0.1,0.1), seed=RANDOM_SEED):\n",
        "    by_cls = defaultdict(list)\n",
        "    for i, label in enumerate(y):\n",
        "        by_cls[label].append(i)\n",
        "    train, val, test = [], [], []\n",
        "    for cls, inds in by_cls.items():\n",
        "        r = random.Random(seed)\n",
        "        r.shuffle(inds)\n",
        "        n = len(inds)\n",
        "        n_train = int(ratios[0]*n)\n",
        "        n_val   = int(ratios[1]*n)\n",
        "        train += inds[:n_train]\n",
        "        val   += inds[n_train:n_train+n_val]\n",
        "        test  += inds[n_train+n_val:]\n",
        "    def take(idxs):\n",
        "        return [X[i] for i in idxs], [y[i] for i in idxs]\n",
        "    return take(train), take(val), take(test)\n",
        "\n",
        "(trainX, trainY), (valX, valY), (testX, testY) = stratified_split(Xc, yc, ratios=(0.8,0.1,0.1), seed=RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "193VOZpiRdlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Stump (categorical)\n",
        "\n",
        "class CatStump:\n",
        "    \"\"\"\n",
        "    h(x) = s * ( 1 if x[f] == cat else -1 ), with s in {+1, -1}\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.feature = None\n",
        "        self.category = None\n",
        "        self.sign = +1  # orientation\n",
        "\n",
        "    def fit_weighted(self, X, y, w):\n",
        "        n = len(X); m = len(X[0])\n",
        "        best_err = 1e9\n",
        "        best = (None, None, +1)\n",
        "        # Precompute categories per feature\n",
        "        for f in range(m):\n",
        "            # collect all categories for this feature\n",
        "            cats = set(x[f] for x in X)\n",
        "            for cat in cats:\n",
        "                # h_pos: predict +1 if equals cat, else -1\n",
        "                err_pos = 0.0\n",
        "                for i in range(n):\n",
        "                    pred = +1 if X[i][f] == cat else -1\n",
        "                    if pred != y[i]:\n",
        "                        err_pos += w[i]\n",
        "                # h_neg: flip orientation (predict -1 if equals cat, else +1)\n",
        "                err_neg = 0.0\n",
        "                for i in range(n):\n",
        "                    pred = -1 if X[i][f] == cat else +1\n",
        "                    if pred != y[i]:\n",
        "                        err_neg += w[i]\n",
        "                if err_pos < best_err:\n",
        "                    best_err = err_pos\n",
        "                    best = (f, cat, +1)\n",
        "                if err_neg < best_err:\n",
        "                    best_err = err_neg\n",
        "                    best = (f, cat, -1)\n",
        "\n",
        "        self.feature, self.category, self.sign = best\n",
        "\n",
        "        # return weighted error found\n",
        "        return best_err\n",
        "\n",
        "    def predict_one(self, x):\n",
        "        hit = (x[self.feature] == self.category)\n",
        "        raw = +1 if hit else -1\n",
        "        return self.sign * raw\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.predict_one(x) for x in X]\n"
      ],
      "metadata": {
        "id": "u8xOiNH1RfRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AdaBoost (SAMME for binary with +/-1 labels)\n",
        "\n",
        "class AdaBoost:\n",
        "    def __init__(self, T=100):\n",
        "        self.T = T\n",
        "        self.learners = []\n",
        "        self.alphas = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n = len(X)\n",
        "        w = [1.0/n]*n\n",
        "        self.learners = []\n",
        "        self.alphas = []\n",
        "        eps = 1e-12\n",
        "        for t in range(self.T):\n",
        "            stump = CatStump()\n",
        "            err = stump.fit_weighted(X, y, w)\n",
        "            err = min(max(err, eps), 1.0 - eps)  # clamp\n",
        "            alpha = 0.5*math.log((1.0 - err)/err)\n",
        "            # update weights\n",
        "            for i in range(n):\n",
        "                pred = stump.predict_one(X[i])\n",
        "                w[i] = w[i] * math.exp(-alpha * y[i] * pred)\n",
        "            # normalize\n",
        "            Z = sum(w)\n",
        "            w = [wi/Z for wi in w]\n",
        "            self.learners.append(stump)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "    def predict_scores(self, X):\n",
        "        # returns real-valued margin sum(alpha_t * h_t(x))\n",
        "        scores = [0.0]*len(X)\n",
        "        for alpha, h in zip(self.alphas, self.learners):\n",
        "            preds = h.predict(X)\n",
        "            for i, p in enumerate(preds):\n",
        "                scores[i] += alpha * p\n",
        "        return scores\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = self.predict_scores(X)\n",
        "        # sign -> {+1, -1}\n",
        "        return [ +1 if s >= 0 else -1 for s in scores ]\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return sum(yt==yp for yt, yp in zip(y_true, y_pred))/len(y_true)\n",
        "\n",
        "def to_label_name_binary(y_pm1):\n",
        "    # map back to strings for readability (optional)\n",
        "    return [\"no-recurrence-events\" if v==+1 else \"recurrence-events\" for v in y_pm1]\n"
      ],
      "metadata": {
        "id": "lpB-MnecRl9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Train / Evaluate ---------\n",
        "\n",
        "ada = AdaBoost(T=150)\n",
        "ada.fit(trainX, trainY)\n",
        "\n",
        "val_pred = ada.predict(valX)\n",
        "test_pred = ada.predict(testX)\n",
        "\n",
        "print(f\"[Breast-Cancer] Validation accuracy: {accuracy(valY, val_pred):.4f}\")\n",
        "print(f\"[Breast-Cancer] Test accuracy:       {accuracy(testY, test_pred):.4f}\")"
      ],
      "metadata": {
        "id": "VNPALjqARq36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46402e1b-a251-481c-8127-1f7261838347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Breast-Cancer] Validation accuracy: 0.6786\n",
            "[Breast-Cancer] Test accuracy:       0.7667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple confusion matrix on test\n",
        "def confusion_matrix_binary(y_true, y_pred):\n",
        "    # +1 = no-recurrence, -1 = recurrence\n",
        "    tp = sum(1 for yt, yp in zip(y_true, y_pred) if yt==+1 and yp==+1)\n",
        "    tn = sum(1 for yt, yp in zip(y_true, y_pred) if yt==-1 and yp==-1)\n",
        "    fp = sum(1 for yt, yp in zip(y_true, y_pred) if yt==-1 and yp==+1)\n",
        "    fn = sum(1 for yt, yp in zip(y_true, y_pred) if yt==+1 and yp==-1)\n",
        "    return {\"TP(+1)\":tp, \"TN(-1)\":tn, \"FP\":fp, \"FN\":fn}\n",
        "\n",
        "print(\"[Breast-Cancer] Test Confusion Matrix:\", confusion_matrix_binary(testY, test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3YQhj0Z6A2D",
        "outputId": "76ae8f87-2753-4c03-c55a-3e8821bfacdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Breast-Cancer] Test Confusion Matrix: {'TP(+1)': 20, 'TN(-1)': 3, 'FP': 6, 'FN': 1}\n"
          ]
        }
      ]
    }
  ]
}